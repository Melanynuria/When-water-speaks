{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce81d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7a23ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly loaded (17,112,709 rows, 12 columns)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "file =\"incidencies_comptadors_intelligents.parquet\"\n",
    "data_dir = \"../data/\"\n",
    "\n",
    "sample_path=os.path.join(data_dir,f\"{file}\")\n",
    "\n",
    "\n",
    "df_ICI=pd.read_parquet(sample_path)\n",
    "print(f\"Correctly loaded ({len(df_ICI):,} rows, {len(df_ICI.columns)} columns)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ed9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error (MAE)\n",
    "def mae(y_true, y_pred):\n",
    "    #average difference between predicted and actual values.\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f4af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root mean squared error\n",
    "def rmse(y_true, y_pred):\n",
    "    #measures the average magnitude of the errors between predicted and actual values\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "001dc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute percentage error \n",
    "def mape(y_true, y_pred):\n",
    "    #percentage error relative to actual values.\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    # avoid division by zero\n",
    "    mask = y_true != 0\n",
    "    if not np.any(mask):\n",
    "        return 0.0\n",
    "    \n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b0f3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean bias error\n",
    "def mean_bias_error(y_true, y_pred):\n",
    "    #average bias in predictions\n",
    "    return np.mean(y_pred - y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1248209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_report(y_true, y_pred, model_name=\"Model\"):\n",
    "    #dictionary to store metrics and print them as a report \n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        'MAE': mae(y_true, y_pred),\n",
    "        'RMSE': rmse(y_true, y_pred),\n",
    "        'MAPE': mape(y_true, y_pred),\n",
    "        'MBE': mean_bias_error(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EVALUATION METRICS: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nRegression Metrics (for {len(y_true)} predictions):\\n\")\n",
    "    print(f\"  MAE (Mean Absolute Error):     {metrics['MAE']:>10.4f}\")\n",
    "    print(f\"  RMSE (Root Mean Squared Error): {metrics['RMSE']:>10.4f}\")\n",
    "    print(f\"  MAPE (Mean Absolute % Error):  {metrics['MAPE']:>10.2f}%\")\n",
    "    print(f\"  MBE (Mean Bias Error):         {metrics['MBE']:>10.4f}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18da5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS FROM 1.3.3\n",
    "def predict_next_month_total_consumption(df_poliza, poliza_id, forecast_days=30):   \n",
    "    # Feature engineering\n",
    "    df_poliza[\"lag_1\"] = df_poliza[\"CONSUMO_REAL\"].shift(1)\n",
    "    df_poliza[\"lag_7\"] = df_poliza[\"CONSUMO_REAL\"].shift(7)\n",
    "    df_poliza[\"rolling_mean_7\"] = (\n",
    "        df_poliza[\"CONSUMO_REAL\"].shift(1).rolling(window=7).mean()\n",
    "    )\n",
    "    df_poliza = df_poliza.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # Model training\n",
    "    features = [\"year\", \"month\", \"day\", \"dayofweek\", \"lag_1\", \"lag_7\", \"rolling_mean_7\"]\n",
    "    target = \"CONSUMO_REAL\"\n",
    "    \n",
    "    X = df_poliza[features]\n",
    "    y = df_poliza[target]\n",
    "    \n",
    "    model = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Forecasting\n",
    "    last_known = df_poliza.iloc[-1].copy()\n",
    "    forecast = []\n",
    "    history = df_poliza.copy()\n",
    "    \n",
    "    for i in range(1, forecast_days + 1):\n",
    "        next_date = last_known[\"FECHA\"] + pd.Timedelta(days=i)\n",
    "        \n",
    "        # Compute features dynamically\n",
    "        recent_data = history.tail(7)[\"CONSUMO_REAL\"]\n",
    "        new_data = {\n",
    "            \"year\": next_date.year,\n",
    "            \"month\": next_date.month,\n",
    "            \"day\": next_date.day,\n",
    "            \"dayofweek\": next_date.dayofweek,\n",
    "            \"lag_1\": history.iloc[-1][\"CONSUMO_REAL\"],\n",
    "            \"lag_7\": recent_data.iloc[0] if len(recent_data) >= 7 else history.iloc[-1][\"CONSUMO_REAL\"],\n",
    "            \"rolling_mean_7\": recent_data.mean()\n",
    "        }\n",
    "        \n",
    "        X_future = pd.DataFrame([new_data])[features]\n",
    "        next_consumption = float(model.predict(X_future)[0])\n",
    "        \n",
    "        new_row = {\n",
    "            \"POLIZA_SUMINISTRO\": poliza_id,\n",
    "            \"FECHA\": next_date,\n",
    "            \"CONSUMO_REAL\": next_consumption,\n",
    "            \"year\": next_date.year,\n",
    "            \"month\": next_date.month,\n",
    "            \"day\": next_date.day,\n",
    "            \"dayofweek\": next_date.dayofweek,\n",
    "            \"is_forecast\": True\n",
    "        }\n",
    "        \n",
    "        forecast.append(new_row)\n",
    "        history = pd.concat([history, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    forecast_df = pd.DataFrame(forecast)\n",
    "    df_poliza[\"is_forecast\"] = False\n",
    "    df_extended = pd.concat([df_poliza, forecast_df], ignore_index=True).sort_values(\"FECHA\")\n",
    "    total_consumption = forecast_df[\"CONSUMO_REAL\"].sum()\n",
    "    \n",
    "    return total_consumption, forecast_df, df_extended, model\n",
    "\n",
    "\n",
    "def call_predict_next_month_total_consumption(df, poliza_id, forecast_days=30):\n",
    "    \n",
    "    df_ = df[[\"POLIZA_SUMINISTRO\", \"FECHA\", \"CONSUMO_REAL\"]].copy()\n",
    "    \n",
    "    # Filter for given POLIZA\n",
    "    df_poliza = df_[df_[\"POLIZA_SUMINISTRO\"] == poliza_id].copy()\n",
    "    if df_poliza.empty:\n",
    "        raise ValueError(f\"No data found for POLIZA_SUMINISTRO = {poliza_id}\")\n",
    "    \n",
    "    df_poliza[\"FECHA\"] = pd.to_datetime(df_poliza[\"FECHA\"])\n",
    "    df_poliza = df_poliza.sort_values(by=\"FECHA\").reset_index(drop=True)\n",
    "    \n",
    "    # Add temporal features\n",
    "    df_poliza[\"year\"] = df_poliza[\"FECHA\"].dt.year\n",
    "    df_poliza[\"month\"] = df_poliza[\"FECHA\"].dt.month\n",
    "    df_poliza[\"day\"] = df_poliza[\"FECHA\"].dt.day\n",
    "    df_poliza[\"dayofweek\"] = df_poliza[\"FECHA\"].dt.dayofweek\n",
    "    \n",
    "    total_consumption, forecast_df, df_extended, model = predict_next_month_total_consumption(\n",
    "        df_poliza, poliza_id, forecast_days\n",
    "    )\n",
    "    \n",
    "    return total_consumption, forecast_df, df_extended, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18393ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(df_train, df_test, poliza_id, forecast_days=30):\n",
    "   #evaluate the model using training and test datasets\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FORECASTING MODEL EVALUATION\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nPolicy ID: {poliza_id}\")\n",
    "    print(f\"Training period: {df_train['FECHA'].min()} to {df_train['FECHA'].max()}\")\n",
    "    print(f\"Test period: {df_test['FECHA'].min()} to {df_test['FECHA'].max()}\")\n",
    "    print(f\"Forecast horizon: {forecast_days} days\")\n",
    "    \n",
    "    # Train model on training data\n",
    "    print(f\"\\n[1/3] Training model on {len(df_train)} samples...\")\n",
    "    total_pred_train, forecast_df_train, _, model = call_predict_next_month_total_consumption(\n",
    "        df_train, poliza_id, forecast_days\n",
    "    )\n",
    "    print(f\"      ✓ Model trained\")\n",
    "    \n",
    "    # Get actual vs predicted for test period\n",
    "    print(f\"\\n[2/3] Making predictions on test period...\")\n",
    "    y_true = df_test[\"CONSUMO_REAL\"].values\n",
    "    y_pred = forecast_df_train[\"CONSUMO_REAL\"].values[:len(df_test)]  # align lengths\n",
    "    \n",
    "    if len(y_pred) > len(y_true):\n",
    "        y_pred = y_pred[:len(y_true)]\n",
    "    elif len(y_pred) < len(y_true):\n",
    "        y_true = y_true[:len(y_pred)]\n",
    "    \n",
    "    print(f\"      ✓ Generated {len(y_pred)} predictions\")\n",
    "    \n",
    "    # Compute metrics\n",
    "    print(f\"\\n[3/3] Computing evaluation metrics...\")\n",
    "    metrics = generate_evaluation_report(y_true, y_pred, f\"XGBoost Forecaster (Policy {poliza_id})\")\n",
    "    \n",
    "    # Additional insights\n",
    "    print(f\"\\nAdditional Insights:\\n\")\n",
    "    print(f\"  Actual consumption (test period):\")\n",
    "    print(f\"    - Mean: {np.mean(y_true):>10.2f} liters/day\")\n",
    "    print(f\"    - Min:  {np.min(y_true):>10.2f} liters/day\")\n",
    "    print(f\"    - Max:  {np.max(y_true):>10.2f} liters/day\")\n",
    "    print(f\"    - Std:  {np.std(y_true):>10.2f} liters/day\")\n",
    "    print(f\"\\n  Predicted consumption (test period):\")\n",
    "    print(f\"    - Mean: {np.mean(y_pred):>10.2f} liters/day\")\n",
    "    print(f\"    - Min:  {np.min(y_pred):>10.2f} liters/day\")\n",
    "    print(f\"    - Max:  {np.max(y_pred):>10.2f} liters/day\")\n",
    "    print(f\"    - Std:  {np.std(y_pred):>10.2f} liters/day\")\n",
    "    \n",
    "    # Error analysis\n",
    "    errors = y_true - y_pred\n",
    "    print(f\"\\n  Error Analysis:\\n\")\n",
    "    print(f\"    - Mean error:      {np.mean(errors):>10.2f} liters/day\")\n",
    "    print(f\"    - Median error:    {np.median(errors):>10.2f} liters/day\")\n",
    "    print(f\"    - Std of errors:   {np.std(errors):>10.2f} liters/day\")\n",
    "    print(f\"    - Max overpredict: {np.max(errors):>10.2f} liters/day\")\n",
    "    print(f\"    - Max underpredict: {np.min(errors):>10.2f} liters/day\")\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'model': model,\n",
    "        'forecast_df': forecast_df_train\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3564b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"WATER CONSUMPTION FORECASTING - MODEL EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n[SETUP] Creating synthetic dataset for demonstration...\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
    "    n_samples = len(dates)\n",
    "    \n",
    "    # Synthetic water consumption with seasonal pattern\n",
    "    base_consumption = 100\n",
    "    seasonal_pattern = 30 * np.sin(np.arange(n_samples) * 2 * np.pi / 365)\n",
    "    noise = np.random.normal(0, 10, n_samples)\n",
    "    consumo_real = base_consumption + seasonal_pattern + noise\n",
    "    consumo_real = np.maximum(consumo_real, 10)  # Ensure positive values\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'POLIZA_SUMINISTRO': ['POL_001'] * n_samples,\n",
    "        'FECHA': dates,\n",
    "        'CONSUMO_REAL': consumo_real\n",
    "    })\n",
    "    \n",
    "    print(f\"      ✓ Dataset created: {len(df)} daily records\")\n",
    "    print(f\"      ✓ Date range: {df['FECHA'].min()} to {df['FECHA'].max()}\")\n",
    "    \n",
    "    # Split train/test (80/20 split, last 30% as test)\n",
    "    split_idx = int(len(df) * 0.70)\n",
    "    df_train = df.iloc[:split_idx].reset_index(drop=True)\n",
    "    df_test = df.iloc[split_idx:split_idx+30].reset_index(drop=True)  # Test on 30 days\n",
    "    \n",
    "    poliza_id = 'POL_001'\n",
    "    forecast_days = len(df_test)\n",
    "    \n",
    "    # Run evaluation\n",
    "    results = evaluate_model(df_train, df_test, poliza_id, forecast_days=forecast_days)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b931ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "WATER CONSUMPTION FORECASTING - MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "[SETUP] Creating synthetic dataset for demonstration...\n",
      "      ✓ Dataset created: 365 daily records\n",
      "      ✓ Date range: 2023-01-01 00:00:00 to 2023-12-31 00:00:00\n",
      "\n",
      "======================================================================\n",
      "FORECASTING MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Policy ID: POL_001\n",
      "Training period: 2023-01-01 00:00:00 to 2023-09-12 00:00:00\n",
      "Test period: 2023-09-13 00:00:00 to 2023-10-12 00:00:00\n",
      "Forecast horizon: 30 days\n",
      "\n",
      "[1/3] Training model on 255 samples...\n",
      "      ✓ Model trained\n",
      "\n",
      "[2/3] Making predictions on test period...\n",
      "      ✓ Generated 30 predictions\n",
      "\n",
      "[3/3] Computing evaluation metrics...\n",
      "\n",
      "============================================================\n",
      "EVALUATION METRICS: XGBoost Forecaster (Policy POL_001)\n",
      "============================================================\n",
      "\n",
      "Regression Metrics (for 30 predictions):\n",
      "\n",
      "  MAE (Mean Absolute Error):        12.7084\n",
      "  RMSE (Root Mean Squared Error):    14.9824\n",
      "  MAPE (Mean Absolute % Error):       20.07%\n",
      "  MBE (Mean Bias Error):             5.9131\n",
      "============================================================\n",
      "\n",
      "\n",
      "Additional Insights:\n",
      "\n",
      "  Actual consumption (test period):\n",
      "    - Mean:      69.62 liters/day\n",
      "    - Min:       38.20 liters/day\n",
      "    - Max:       91.80 liters/day\n",
      "    - Std:       11.28 liters/day\n",
      "\n",
      "  Predicted consumption (test period):\n",
      "    - Mean:      75.54 liters/day\n",
      "    - Min:       65.52 liters/day\n",
      "    - Max:       85.55 liters/day\n",
      "    - Std:        5.25 liters/day\n",
      "\n",
      "  Error Analysis:\n",
      "\n",
      "    - Mean error:           -5.91 liters/day\n",
      "    - Median error:         -6.16 liters/day\n",
      "    - Std of errors:        13.77 liters/day\n",
      "    - Max overpredict:      18.04 liters/day\n",
      "    - Max underpredict:     -29.43 liters/day\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
